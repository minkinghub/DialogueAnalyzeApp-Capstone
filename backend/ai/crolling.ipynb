{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 크롤링\n",
    "import requests\n",
    "import csv\n",
    "import json\n",
    "\n",
    "# API 주소(요리명과 조리 방법)를 통해 데이터 긁어와 csv로 저장하는 코드\n",
    "url = \"http://openapi.foodsafetykorea.go.kr/api/439dfa58a5bd4e228198/COOKRCP01/json/1001/2000\"\n",
    "\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "recipes = data['COOKRCP01']['row']\n",
    "\n",
    "with open('recipe2.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    headers = recipes[0].keys()\n",
    "    writer.writerow(headers)\n",
    "\n",
    "    for recipe in recipes:\n",
    "        writer.writerow(recipe.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정제\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('ingredient.csv', encoding='cp949')\n",
    "\n",
    "# 대표 식품명 기준 1개만 남기고 나머지 삭제\n",
    "data = data.drop_duplicates(subset='대표식품명', keep='first')\n",
    "\n",
    "# 새로운 CSV로 저장\n",
    "data.to_csv('new_ingredient.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 번 더 정제\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('new_ingredient.csv')\n",
    "\n",
    "# '식품명' 열의 값 정제\n",
    "data['식품명'] = data['식품명'].str.split('_').str[0] # _과 그 이후 단어 삭제\n",
    "data['식품명'] = data['식품명'].str.split('(').str[0] # (와 그 이후 단어 삭제\n",
    "\n",
    "data.to_csv('final_ingredient.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 진짜 마지막 정제  \n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('final_ingredient.csv')\n",
    "\n",
    "# '식품명'에서 ~류 삭제\n",
    "data['식품명'] = data['식품명'].str.split('류').str[0] # ~류 삭제\n",
    "\n",
    "data.to_csv('real_final_ingredient.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recipe 정제\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('recipe.csv')\n",
    "\n",
    "cut_list = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if pd.isnull(row['RCP_PARTS_DTLS']):\n",
    "        continue # NAN 값이면 건너뛰기\n",
    "    first_char = row['RCP_PARTS_DTLS'][0] # 첫 번째 문자 추출\n",
    "    if first_char in [':', ')', ']', '(', '[']: # 첫 번째 문자가 특수문자인지 확인\n",
    "        cut_list.append(first_char) # 첫 번째 문자를 cut_list에 추가\n",
    "        df.loc[idx, 'RCP_PARTS_DTLS'] = row['RCP_PARTS_DTLS'][1:].strip() # 첫 번째 문자 제거\n",
    "\n",
    "# 잘라낸 내용을 따로 csv로 저장\n",
    "cut_df = pd.DataFrame(cut_list, columns=['cut'])\n",
    "cut_df.to_csv('cut.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# 나머지 내용을 새로운 csv로 저장\n",
    "df.to_csv('new_recipe.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세미콜론 가준으로 MAIN, SUB 등으로 쪼개기\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def split_data(data):\n",
    "    # NaN 값이나 숫자 값을 검사\n",
    "    if pd.isna(data) or isinstance(data, (int, float)):\n",
    "        return {\"RCP_MAIN\": \"\", \"RCP_SUB1\": \"\", \"RCP_SUB2\": \"\", \"RCP_SUB3\": \"\", \"RCP_SUB4\": \"\", \"RCP_SUB5\": \"\"}\n",
    "    \n",
    "    data = re.sub(r'\\b\\w+\\s*:', ':', data)\n",
    "    \n",
    "    parts = data.split(':')\n",
    "    result = {\"RCP_MAIN\": \"\", \"RCP_SUB1\": \"\", \"RCP_SUB2\": \"\", \"RCP_SUB3\": \"\", \"RCP_SUB4\": \"\", \"RCP_SUB5\": \"\"}\n",
    "    for i, part in enumerate(parts):\n",
    "        if i == 0:\n",
    "            result[\"RCP_MAIN\"] = part.strip()\n",
    "        elif i == 1:\n",
    "            result[\"RCP_SUB1\"] = part.strip()\n",
    "        elif i == 2:\n",
    "            result[\"RCP_SUB2\"] = part.strip()\n",
    "        elif i == 3:\n",
    "            result[\"RCP_SUB3\"] = part.strip()\n",
    "        elif i == 4:\n",
    "            result[\"RCP_SUB4\"] = part.strip()\n",
    "        elif i == 5:\n",
    "            result[\"RCP_SUB5\"] = part.strip()\n",
    "    return result\n",
    "\n",
    "df = pd.read_csv('recipe.csv')\n",
    "\n",
    "df_cut = df['RCP_PARTS_DTLS'].apply(split_data).apply(pd.Series)\n",
    "\n",
    "df_cut.to_csv('cut.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def split_data(data):\n",
    "    # NaN 값이나 숫자 값을 검사\n",
    "    if pd.isna(data) or isinstance(data, (int, float)):\n",
    "        return {\"RCP_MAIN\": \"\", \"RCP_SUB1\": \"\", \"RCP_SUB2\": \"\", \"RCP_SUB3\": \"\", \"RCP_SUB4\": \"\", \"RCP_SUB5\": \"\"}\n",
    "\n",
    "    data = re.sub(r'\\b\\w+\\s*:', ':', data)\n",
    "\n",
    "    parts = data.split(':')\n",
    "    result = {\"RCP_MAIN\": \"\", \"RCP_SUB1\": \"\", \"RCP_SUB2\": \"\", \"RCP_SUB3\": \"\", \"RCP_SUB4\": \"\", \"RCP_SUB5\": \"\"}\n",
    "    for i, part in enumerate(parts):\n",
    "        if i == 0:\n",
    "            result[\"RCP_MAIN\"] = part.strip()\n",
    "        elif i == 1:\n",
    "            result[\"RCP_SUB1\"] = part.strip()\n",
    "        elif i == 2:\n",
    "            result[\"RCP_SUB2\"] = part.strip()\n",
    "        elif i == 3:\n",
    "            result[\"RCP_SUB3\"] = part.strip()\n",
    "        elif i == 4:\n",
    "            result[\"RCP_SUB4\"] = part.strip()\n",
    "        elif i == 5:\n",
    "            result[\"RCP_SUB5\"] = part.strip()\n",
    "    return result\n",
    "\n",
    "df = pd.read_csv('recipe.csv')\n",
    "\n",
    "df_cut = df['RCP_PARTS_DTLS'].apply(split_data).apply(pd.Series)\n",
    "\n",
    "# 기존 df에 새로 생성된 df_cut을 결합\n",
    "df = pd.concat([df, df_cut], axis=1)\n",
    "\n",
    "df.to_csv('cut.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'RCP_MAIN' 열에서 값이 존재하지 않는 행의 위치: Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# 특정 열에 값이 비어있는 지 찾고, 그 위치 반환하기\n",
    "import pandas as pd\n",
    "\n",
    "# cut.csv 파일 읽기\n",
    "df_cut = pd.read_csv('new_recipe.csv')\n",
    "\n",
    "# 'RCP_SUB3' 열에서 값이 존재하지 않는 행 찾기\n",
    "non_existing_values = df_cut['RCP_MAIN'].isna()\n",
    "\n",
    "# 값이 존재하지 않는 행의 위치 찾기\n",
    "rows_without_value = non_existing_values[non_existing_values].index\n",
    "\n",
    "# 위치 정보 출력 (1부터 시작하도록 +1)\n",
    "print(f\"'RCP_MAIN' 열에서 값이 존재하지 않는 행의 위치: {rows_without_value + 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RCP 방법 열에서 특정 특수문자(?, -)와 그 특수문자와 붙은 단어 삭제하기\n",
    "import pandas as pd\n",
    "import re \n",
    "\n",
    "df = pd.read_csv('new_recipe.csv')\n",
    "\n",
    "# 'RCP_MAIN', 'RCP_SUB1', 'RCP_SUB2', 'RCP_SUB3', 'RCP_SUB4', 'RCP_SUB5' 열에서 특수문자(`?`, `-`)와 그 뒤의 모든 문자 삭제\n",
    "columns = ['RCP_MAIN', 'RCP_SUB1', 'RCP_SUB2', 'RCP_SUB3', 'RCP_SUB4', 'RCP_SUB5']\n",
    "for column in columns:\n",
    "    df[column] = df[column].replace(to_replace=r'[?-].*', value='', regex=True)\n",
    "\n",
    "df.to_csv('recipe_new.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# recut.csv 파일 읽기\n",
    "df = pd.read_csv('recipe2.csv')\n",
    "\n",
    "# 여러 열을 하나로 합치기\n",
    "df['RCP_PARTS_DTLS'] = df[['RCP_MAIN', 'RCP_SUB1', 'RCP_SUB2', 'RCP_SUB3', 'RCP_SUB4', 'RCP_SUB5']].apply(lambda row: ':'.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "# ':nan' 문자열 삭제\n",
    "df['RCP_PARTS_DTLS'] = df['RCP_PARTS_DTLS'].str.replace(':nan', '')\n",
    "\n",
    "# ':' 문자열을 ',' 문자열로 치환\n",
    "df['RCP_PARTS_DTLS'] = df['RCP_PARTS_DTLS'].str.replace(':', ', ')\n",
    "\n",
    "# 'RCP_MAIN', 'RCP_SUB1', 'RCP_SUB2', 'RCP_SUB3', 'RCP_SUB4', 'RCP_SUB5' 열 삭제\n",
    "df = df.drop(columns=['RCP_MAIN', 'RCP_SUB1', 'RCP_SUB2', 'RCP_SUB3', 'RCP_SUB4', 'RCP_SUB5'])\n",
    "\n",
    "# 결과를 recut.csv 파일에 저장\n",
    "df.to_csv('cut.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'RCP_PARTS_DTLS' 열에서 값이 존재하지 않는 행의 위치: Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# csv 특정 열에 값이 몇 개 비어있는 지 세고, 그 위치 반환하기\n",
    "import pandas as pd\n",
    "\n",
    "# cut.csv 파일 읽기\n",
    "df_cut = pd.read_csv('recipe.csv')\n",
    "\n",
    "# 'RCP_PARTS_DTLS' 열에서 값이 존재하지 않는 행 찾기\n",
    "non_existing_values = df_cut['RCP_PARTS_DTLS'].isna()\n",
    "\n",
    "# 값이 존재하지 않는 행의 위치 찾기\n",
    "rows_without_value = non_existing_values[non_existing_values].index\n",
    "\n",
    "# 위치 정보 출력 (1부터 시작하도록 +1)\n",
    "print(f\"'RCP_PARTS_DTLS' 열에서 값이 존재하지 않는 행의 위치: {rows_without_value + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 콤마 정제 1탄: g 뒤에 콤마 없으면 붙이기\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# recut.csv 파일 읽기\n",
    "df = pd.read_csv('CUT.csv')\n",
    "\n",
    "# 줄바꿈 문자가 있는 문자열 찾기\n",
    "df['RCP_PARTS_DTLS'] = df['RCP_PARTS_DTLS'].apply(lambda x: re.sub(r'g(?![:,])', 'g,', x) if pd.notnull(x) else x)\n",
    "\n",
    "# 결과를 recut.csv 파일에 저장\n",
    "df.to_csv('recut.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# recut.csv 파일 읽기\n",
    "df = pd.read_csv('recipe.csv')\n",
    "\n",
    "# 문장의 맨 앞에 콤마가 있는 경우 삭제\n",
    "df['RCP_PARTS_DTLS'] = df['RCP_PARTS_DTLS'].apply(lambda x: re.sub(r'^,', '', x) if pd.notnull(x) else x)\n",
    "\n",
    "# g 뒤에 콤마가 아닌 다른 문자가 오면 g 뒤에 콤마를 붙이되, 띄어쓰기와 줄바꿈은 제외\n",
    "df['RCP_PARTS_DTLS'] = df['RCP_PARTS_DTLS'].apply(lambda x: re.sub(r'g(?![:,\\s])', 'g,', x) if pd.notnull(x) else x)\n",
    "\n",
    "# 결과를 recut.csv 파일에 저장\n",
    "df.to_csv('cut.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# recipe.csv 파일 읽기\n",
    "df = pd.read_csv('recipe.csv')\n",
    "\n",
    "# RCP_PARTS_DTLS에 있는 콤마를 전부 삭제\n",
    "df['RCP_PARTS_DTLS'] = df['RCP_PARTS_DTLS'].apply(lambda x: re.sub(',', '', x) if pd.notnull(x) else x)\n",
    "\n",
    "# g 뒤에 콤마를 다 붙임\n",
    "df['RCP_PARTS_DTLS'] = df['RCP_PARTS_DTLS'].apply(lambda x: re.sub('g', 'g,', x) if pd.notnull(x) else x)\n",
    "\n",
    "# 문장에 맨 끝에 오는 콤마는 삭제\n",
    "df['RCP_PARTS_DTLS'] = df['RCP_PARTS_DTLS'].apply(lambda x: re.sub(',$', '', x) if pd.notnull(x) else x)\n",
    "\n",
    "# 결과를 recipe.csv 파일에 저장\n",
    "df.to_csv('cut.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhy97\\AppData\\Local\\Temp\\ipykernel_4392\\4098798430.py:10: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  soup = BeautifulSoup(response.text, 'lxml')\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "# API 요청\n",
    "url = \"https://apis.data.go.kr/B551182/diseaseInfoService/getDissNameCodeList?serviceKey=e4ZK69MusxTk8Rk0s0US%2Bc9uLgmYzyvmC4%2F4cFXVlWm6emK8KIQDH8TA1I8zv173L1YHFn4SU8P9cd217BWT5g%3D%3D&numOfRows=3000&pageNo=1&year=2022&sickCd=A00&sickType=1&medTp=1\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "# BeautifulSoup으로 파싱\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "# 데이터 추출\n",
    "items = soup.find_all('item')\n",
    "data = []\n",
    "for item in items:\n",
    "    sickCd = item.find('sickcd').text\n",
    "    sickNm = item.find('sicknm').text\n",
    "    data.append([sickCd, sickNm])\n",
    "\n",
    "# 데이터 프레임 생성\n",
    "df = pd.DataFrame(data, columns=['sickCd', 'sickNm'])\n",
    "\n",
    "# CSV 파일로 저장\n",
    "df.to_csv('disease.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
