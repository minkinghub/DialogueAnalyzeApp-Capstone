{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jhy97\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "특징 추출: 100%|██████████| 10011/10011 [05:23<00:00, 30.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features 배열의 길이: 10011\n",
      "모델 학습 중...\n",
      "모델 평가 중...\n",
      "Accuracy: 0.4588117823265102\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "data = pd.read_csv('emotion.csv')\n",
    "\n",
    "# 음성 데이터 특징 추출 함수\n",
    "def extract_features(wav_id):\n",
    "    file_path = f'sound/{wav_id}.wav'  # 수정된 파일 경로\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        chroma = librosa.feature.chroma_stft(y=audio, sr=sample_rate)\n",
    "        mel = librosa.feature.melspectrogram(y=audio, sr=sample_rate)\n",
    "        contrast = librosa.feature.spectral_contrast(y=audio, sr=sample_rate)\n",
    "        tonnetz = librosa.feature.tonnetz(y=audio, sr=sample_rate)\n",
    "        features = np.mean(np.concatenate([mfccs, chroma, mel, contrast, tonnetz], axis=0), axis=1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while parsing file: {file_path}, {e}\")\n",
    "        return None\n",
    "    return features\n",
    "\n",
    "# 병렬 처리를 사용하여 모든 음성 파일에 대해 특징 추출 수행\n",
    "features = Parallel(n_jobs=-1)(delayed(extract_features)(wav_id) for wav_id in tqdm(data['wav_id'], desc=\"특징 추출\"))\n",
    "\n",
    "# None 값을 제거하고 numpy 배열로 변환\n",
    "features = np.array([x for x in features if x is not None])\n",
    "\n",
    "# features 배열의 길이 확인\n",
    "print(f\"Features 배열의 길이: {len(features)}\")\n",
    "\n",
    "# 라벨 준비\n",
    "y = data['1번 감정'].values\n",
    "\n",
    "# 데이터셋 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 학습\n",
    "print(\"모델 학습 중...\")\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "print(\"모델 평가 중...\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "# 정확도 0.45\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "data = pd.read_csv('emotion.csv')\n",
    "\n",
    "data['성별'] = data['성별'].map({'female': 0, 'male': 1})\n",
    "\n",
    "# LabelEncoder 인스턴스 생성\n",
    "le = LabelEncoder()\n",
    "\n",
    "# '상황', '1번 감정' ~ '5번 감정' 열에 대해 Label encoding 적용\n",
    "for col in ['상황', '1번 감정', '2번 감정', '3번 감정', '4번 감정', '5번 감정']:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "\n",
    "\n",
    "\n",
    "# 음성 데이터 특징 추출 함수\n",
    "def extract_features(wav_id):\n",
    "    file_path = f'sound/{wav_id}.wav'\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        chroma = librosa.feature.chroma_stft(y=audio, sr=sample_rate)\n",
    "        mel = librosa.feature.melspectrogram(y=audio, sr=sample_rate)\n",
    "        contrast = librosa.feature.spectral_contrast(y=audio, sr=sample_rate)\n",
    "        tonnetz = librosa.feature.tonnetz(y=audio, sr=sample_rate)\n",
    "        features = np.mean(np.concatenate([mfccs, chroma, mel, contrast, tonnetz], axis=0), axis=1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while parsing file: {file_path}, {e}\")\n",
    "        return None\n",
    "    return features\n",
    "\n",
    "# 병렬 처리를 사용하여 모든 음성 파일에 대해 특징 추출 수행\n",
    "features = Parallel(n_jobs=-1)(delayed(extract_features)(wav_id) for wav_id in tqdm(data['wav_id'], desc=\"특징 추출\"))\n",
    "\n",
    "# None 값을 제거하고 numpy 배열로 변환\n",
    "features = np.array([x for x in features if x is not None])\n",
    "\n",
    "# 데이터셋 분할\n",
    "X = features  # 앞서 추출한 특징(features) 사용\n",
    "y = data[['상황', '1번 감정', '2번 감정', '3번 감정', '4번 감정', '5번 감정', '1번 감정세기', '2번 감정세기', '3번 감정세기', '4번감정세기', '5번 감정세기', '나이', '성별']].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 학습\n",
    "model = MultiOutputClassifier(RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "특징 추출: 100%|██████████| 10011/10011 [04:12<00:00, 39.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 0 정확도: 0.5841238142785822\n",
      "레이블 1 정확도: 0.4588117823265102\n",
      "레이블 2 정확도: 0.6010983524712931\n",
      "레이블 3 정확도: 0.7908137793310035\n",
      "레이블 4 정확도: 0.6160758861707439\n",
      "레이블 5 정확도: 0.5896155766350474\n",
      "레이블 6 정확도: 0.5551672491263105\n",
      "레이블 7 정확도: 0.6245631552670994\n",
      "레이블 8 정확도: 0.800798801797304\n",
      "레이블 9 정확도: 0.8831752371442836\n",
      "레이블 10 정확도: 0.7888167748377434\n",
      "레이블 11 정확도: 0.9745381927109336\n",
      "레이블 12 정확도: 0.9950074887668497\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "data = pd.read_csv('emotion.csv')\n",
    "\n",
    "data['성별'] = data['성별'].map({'female': 0, 'male': 1})\n",
    "\n",
    "# LabelEncoder 인스턴스 생성\n",
    "le = LabelEncoder()\n",
    "\n",
    "# '상황', '1번 감정' ~ '5번 감정' 열에 대해 Label encoding 적용\n",
    "for col in ['상황', '1번 감정', '2번 감정', '3번 감정', '4번 감정', '5번 감정']:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "\n",
    "# 음성 데이터 특징 추출 함수\n",
    "def extract_features(wav_id):\n",
    "    file_path = f'sound/{wav_id}.wav'\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        chroma = librosa.feature.chroma_stft(y=audio, sr=sample_rate)\n",
    "        mel = librosa.feature.melspectrogram(y=audio, sr=sample_rate)\n",
    "        contrast = librosa.feature.spectral_contrast(y=audio, sr=sample_rate)\n",
    "        tonnetz = librosa.feature.tonnetz(y=audio, sr=sample_rate)\n",
    "        features = np.mean(np.concatenate([mfccs, chroma, mel, contrast, tonnetz], axis=0), axis=1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while parsing file: {file_path}, {e}\")\n",
    "        return None\n",
    "    return features\n",
    "\n",
    "# 병렬 처리를 사용하여 모든 음성 파일에 대해 특징 추출 수행\n",
    "features = Parallel(n_jobs=-1)(delayed(extract_features)(wav_id) for wav_id in tqdm(data['wav_id'], desc=\"특징 추출\"))\n",
    "\n",
    "# None 값을 제거하고 numpy 배열로 변환\n",
    "features = np.array([x for x in features if x is not None])\n",
    "\n",
    "# None 값이 제거된 행에 해당하는 y 값 선택\n",
    "valid_rows = [i for i, x in enumerate(features) if x is not None]\n",
    "y = data.iloc[valid_rows][['상황', '1번 감정', '2번 감정', '3번 감정', '4번 감정', '5번 감정', '1번 감정세기', '2번 감정세기', '3번 감정세기', '4번감정세기', '5번 감정세기', '나이', '성별']].values\n",
    "\n",
    "# 데이터셋 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 학습\n",
    "model = MultiOutputClassifier(RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 예측된 결과와 실제 값을 비교하여 각 레이블에 대한 정확도를 계산\n",
    "for i in range(y_test.shape[1]):\n",
    "    label_accuracy = accuracy_score(y_test[:, i], y_pred[:, i])\n",
    "    print(f'레이블 {i} 정확도: {label_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 첫 번째 타겟에 대한 특징 중요도 추출\n",
    "feature_importances = model.estimators_[0].feature_importances_\n",
    "\n",
    "# 특징 중요도 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(feature_importances)), feature_importances)\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importance for the First Target')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성별: 여성\n",
      "상황 키워드: 진로,취업,직장\n",
      "신체 질환: 해당없음\n",
      "감정 대분류: 분노\n",
      "감정 소분류: 노여워하는\n",
      "대화 내용:\n",
      "  대화 1 - 사람: 일은 왜 해도 해도 끝이 없을까? 화가 난다.\n",
      "         시스템: 많이 힘드시겠어요. 주위에 의논할 상대가 있나요?\n",
      "  대화 2 - 사람: 그냥 내가 해결하는 게 나아. 남들한테 부담 주고 싶지도 않고.\n",
      "         시스템: 혼자 해결하기로 했군요. 혼자서 해결하기 힘들면 주위에 의논할 사람을 찾아보세요.\n"
     ]
    }
   ],
   "source": [
    "# 대화 데이터 구조를 정의하는 클래스\n",
    "class Conversation:\n",
    "    def __init__(self, gender, keywords, health_condition, emotion_main, emotion_sub, sentences):\n",
    "        self.gender = gender\n",
    "        self.keywords = keywords\n",
    "        self.health_condition = health_condition\n",
    "        self.emotion_main = emotion_main\n",
    "        self.emotion_sub = emotion_sub\n",
    "        self.sentences = sentences  # 사람과 시스템의 문장 쌍을 리스트로 저장\n",
    "\n",
    "# 대화 내용을 분석하는 함수\n",
    "def analyze_conversation(conversation):\n",
    "    print(\"성별:\", conversation.gender)\n",
    "    print(\"상황 키워드:\", conversation.keywords)\n",
    "    print(\"신체 질환:\", conversation.health_condition)\n",
    "    print(\"감정 대분류:\", conversation.emotion_main)\n",
    "    print(\"감정 소분류:\", conversation.emotion_sub)\n",
    "    print(\"대화 내용:\")\n",
    "    for i, (person_sentence, system_sentence) in enumerate(conversation.sentences, 1):\n",
    "        print(f\"  대화 {i} - 사람: {person_sentence}\")\n",
    "        print(f\"         시스템: {system_sentence}\")\n",
    "\n",
    "# 샘플 대화 데이터 생성\n",
    "sample_conversation = Conversation(\n",
    "    gender=\"여성\",\n",
    "    keywords=\"진로,취업,직장\",\n",
    "    health_condition=\"해당없음\",\n",
    "    emotion_main=\"분노\",\n",
    "    emotion_sub=\"노여워하는\",\n",
    "    sentences=[\n",
    "        (\"일은 왜 해도 해도 끝이 없을까? 화가 난다.\", \"많이 힘드시겠어요. 주위에 의논할 상대가 있나요?\"),\n",
    "        (\"그냥 내가 해결하는 게 나아. 남들한테 부담 주고 싶지도 않고.\", \"혼자 해결하기로 했군요. 혼자서 해결하기 힘들면 주위에 의논할 사람을 찾아보세요.\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 샘플 대화 분석 실행\n",
    "analyze_conversation(sample_conversation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
